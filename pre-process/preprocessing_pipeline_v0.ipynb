{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e827528f-8eec-4e63-85f9-f0ce9f37bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import miceforest as mf\n",
    "import re\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8857fb-21b1-4edb-b773-3134f1b824b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24471, 500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df0 = pd.read_csv(\"data/anticonflict_study_dataframe.csv\",low_memory=False)\n",
    "study_df = study_df0.copy()\n",
    "study_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254cfa6f-c833-4a23-bff2-574d86ed6ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22721, 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coercing values which indicate errors or missingness to NaN\n",
    "study_df = pd.DataFrame(study_df.apply(lambda x: np.where(x.isin([\n",
    "    \"-99              \", \"-77              \",\"\",\"-98              \",\"-97              \",\n",
    "    \"-55              \",\"-88              \",\"-66              \",\"[MASKED BY ICPSR]\"]),np.nan,x)))\n",
    "\n",
    "#dropping columns where over 50% of values are NaN, rows where all values are NaN,\n",
    "#and rows where student IDs are invalid\n",
    "#study_df.drop(columns=study_df.columns[(study_df.isna()).mean()>0.5].values, inplace=True)\n",
    "study_df = study_df[~(study_df.isna()).all(1)]\n",
    "study_df = study_df[(study_df[\"ID\"] != \"--blank--\") & (study_df[\"ID\"] != \"999\")]\n",
    "study_df.dropna(subset=[\"ID\",\"TREAT\",\"SCHTREAT\"],inplace=True)\n",
    "\n",
    "study_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c57c95-7471-4916-a862-0d4cb148df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe based on relevant variables, selected for their\n",
    "#importance in the causal graph\n",
    "relevant_vars = pd.read_csv(\"data/Limited_VariableInclusion250_v2.csv\",header=None)[0].unique()\n",
    "relevant_vars3 = [col.translate({ord(\"(\"):\"\",ord(\")\"):\"\"}).upper() for col in relevant_vars]\n",
    "\n",
    "mtest_df = (study_df.copy())[relevant_vars3]\n",
    "mtest_noms = [col for col in mtest_df.columns if (\"ST\" in col) & (\"CN\" in col)]\n",
    "mtest_df.drop(columns=mtest_noms,inplace=True)\n",
    "mtest_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412368a2-ae28-4ae3-910f-518e07f5dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe based on a list of variables that will factor\n",
    "#into our \"Final Anti-conflict Score\" response variable\n",
    "response_var_list = pd.read_csv(\"data/Response_VariableInclusion250.csv\",header=None)[0]\n",
    "response_var_names = [str(col).translate({ord(\"(\"):\"\",ord(\")\"):\"\"}).upper() for col in response_var_list]\n",
    "mtest_response = mtest_df[response_var_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b689be5e-14bb-4a4f-84fc-057e534e6f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DN1W2</th>\n",
       "      <th>DN2W2</th>\n",
       "      <th>DN3W2</th>\n",
       "      <th>DN4W2</th>\n",
       "      <th>DN5W2</th>\n",
       "      <th>DN6W2</th>\n",
       "      <th>DN7W2</th>\n",
       "      <th>DN8W2</th>\n",
       "      <th>DN9W2</th>\n",
       "      <th>DN10W2</th>\n",
       "      <th>...</th>\n",
       "      <th>DE43</th>\n",
       "      <th>DE44</th>\n",
       "      <th>DE45</th>\n",
       "      <th>DE46</th>\n",
       "      <th>DE47</th>\n",
       "      <th>DE48</th>\n",
       "      <th>DE49</th>\n",
       "      <th>DE50</th>\n",
       "      <th>DE51</th>\n",
       "      <th>DE98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(4) Every day</td>\n",
       "      <td>(4) Every day</td>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(2) About 1 time/week</td>\n",
       "      <td>(1) 1-2 times/month</td>\n",
       "      <td>(2) About 1 time/week</td>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(4) Every day</td>\n",
       "      <td>(0) Never</td>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(4) Every day</td>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(1) 1-2 times/month</td>\n",
       "      <td>(1) 1-2 times/month</td>\n",
       "      <td>(3) 2-3 times/week</td>\n",
       "      <td>(1) 1-2 times/month</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DN1W2          DN2W2          DN3W2               DN4W2  \\\n",
       "0  (3) 2-3 times/week  (4) Every day  (4) Every day  (3) 2-3 times/week   \n",
       "1  (3) 2-3 times/week  (4) Every day      (0) Never  (3) 2-3 times/week   \n",
       "\n",
       "                   DN5W2                DN6W2                  DN7W2  \\\n",
       "0  (2) About 1 time/week  (1) 1-2 times/month  (2) About 1 time/week   \n",
       "1          (4) Every day   (3) 2-3 times/week    (1) 1-2 times/month   \n",
       "\n",
       "                 DN8W2               DN9W2               DN10W2  ... DE43  \\\n",
       "0   (3) 2-3 times/week  (3) 2-3 times/week   (3) 2-3 times/week  ...    0   \n",
       "1  (1) 1-2 times/month  (3) 2-3 times/week  (1) 1-2 times/month  ...    0   \n",
       "\n",
       "  DE44 DE45 DE46 DE47 DE48 DE49 DE50 DE51 DE98  \n",
       "0    0    0    0    0    0    3    0    0    0  \n",
       "1    0    0    0    0    0   11    0    0    0  \n",
       "\n",
       "[2 rows x 129 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add variables that represent school records of students' conflicts;\n",
    "#create a new variable to capture total instances of conflict\n",
    "de_var_names = [col for col in mtest_response.columns if \"DE\" in col]\n",
    "de_imputed = mtest_response.loc[:,de_var_names].apply(lambda x: np.where(x.isna(),0,x.fillna(0).astype(int)))\n",
    "mtest_response = pd.concat([mtest_response.drop(columns=de_var_names),de_imputed],axis=1)\n",
    "mtest_response.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52cc610-6622-4a1c-b5e0-a64f03905911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNCL5W2_DUMMY1    0.419788\n",
       "DNCL4W2_DUMMY1    0.419788\n",
       "DNCL1W2_DUMMY1    0.419788\n",
       "DNCL3W2_DUMMY1    0.419788\n",
       "DNCL7W2_DUMMY1    0.419788\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dummy variables for the response variables, since most are categorical\n",
    "#include additional indicator variables for missing values\n",
    "r_dummy_df = pd.get_dummies(mtest_response,drop_first=True,prefix_sep='_DUMMY',dummy_na=True)\n",
    "r_dummy_df.columns = [((col.split()[0])).translate({ord(\"(\"):\"\",ord(\")\"):\"\",ord(\"[\"):\"\",ord(\"]\"):\"\"})\\\n",
    "                    for col in (r_dummy_df.columns)]\n",
    "\n",
    "def retain_nans(x):\n",
    "    \"\"\"\n",
    "    Takes a series produced by get_dummies(), uses the NaN columns\n",
    "    such that missing values are preserved as missing and returns the series with preserved\n",
    "    missingness. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.where(r_dummy_df[x.name[:-1]+\"nan\"]==1,np.nan,x)\n",
    "    except:\n",
    "        #print(\"Except: \"+x.name+\" -- with \"+x.name[:-1]+\"nan\")\n",
    "        return x\n",
    "\n",
    "#retain missingness in the response variables, drop dummy NaN columns\n",
    "r_dummy_df = r_dummy_df.apply(lambda x: retain_nans(x))\n",
    "r_dummy_df = r_dummy_df.loc[:,~r_dummy_df.columns.str.endswith(\"nan\")]\n",
    "\n",
    "r_dummy_df.isna().mean().sort_values().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec66005-2174-4f19-a342-8f7605d9e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Q 3.4 -- missing data imputation)\n",
    "def fit_mice(dummy_df):\n",
    "    \"\"\"\n",
    "    Given a dataframe of dummy variables with retained missingness,\n",
    "    use the miceforest package's MICE algorithm to impute missing \n",
    "    values five separate times. Return an array of impited dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    #creates a MICE imputation kernel based on the dummy dataframe\n",
    "    #plans to create five seperate dataframes based on different\n",
    "    #randomly produced results by the random forests underlying the\n",
    "    #algorithm. See the package documenation for further information:\n",
    "    #https://miceforest.readthedocs.io/en/latest/\n",
    "    kernel = mf.ImputationKernel(\n",
    "      dummy_df,\n",
    "      datasets=5,\n",
    "      save_all_iterations=True,\n",
    "      random_state=396\n",
    "    )\n",
    "    \n",
    "    #run the imputaton algorithm five times\n",
    "    kernel.mice(5)\n",
    "\n",
    "    for k in range(5):\n",
    "        results.append(kernel.complete_data(k))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2d0362-fb5a-4e20-af33-a072550bfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dummy_df.to_csv(\"data/full_unimputed_response_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26af4abb-b3fd-4faa-a093-1b626b745811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENDER      0.000880\n",
       "GR          0.000880\n",
       "AGEC_NEW    0.012411\n",
       "COLL        0.026055\n",
       "PN1         0.029576\n",
       "              ...   \n",
       "DNCL3       0.291492\n",
       "DNCL1       0.291492\n",
       "DNCL6       0.291492\n",
       "DNCL5       0.291492\n",
       "DNCL7       0.291492\n",
       "Length: 72, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get relevant explanatory variables, selecting both individually\n",
    "#identified variables and variables from the first survey\n",
    "exo_mtest_df = pd.concat([mtest_df.loc[:,relevant_vars3[5:12]],\n",
    "                          study_df[[col.replace(\"W2\",\"\") for col in response_var_names\\\n",
    "                                    if ((\"W2\" in col)&(col.replace(\"W2\",\"\") in study_df.columns))]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb7f47f-7e48-45e4-a585-642dcfb3d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummy variables and run retain_nans(x) to preserve \n",
    "#column missingness\n",
    "e_dummy_df = pd.get_dummies(exo_mtest_df,drop_first=True,dummy_na=True)\n",
    "e_dummy_df = e_dummy_df.apply(lambda x: retain_nans(x))\n",
    "e_dummy_df = e_dummy_df.loc[:,~e_dummy_df.columns.str.endswith(\"nan\")]\n",
    "\n",
    "#run the MICE random forest algorithm\n",
    "e_imputed_df = fit_mice(e_dummy_df)\n",
    "\n",
    "#save the imputed dataframes\n",
    "for k in range(5):\n",
    "    e_imputed_df[k].to_csv((\"data/full_imputed_predictor_df_iter\"+str(k)+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffbfd534-cb4c-4ad0-95ef-f9e1632e2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifies treatment variables and index variables in the dataset\n",
    "roots_vars = [col for col in study_df if \\\n",
    "              ((\"RTSM\" in col)|(col==\"ID\")|(col==\"SCHID\")|(col==\"TREAT\")|\\\n",
    "              (col==\"SCHTREAT\")|(col==\"UID\"))]\n",
    "\n",
    "#filters based on treatment variables, coerces series to \n",
    "#appropriate data types\n",
    "study_df_trt = study_df.loc[:,roots_vars]\n",
    "study_df_trt[\"ID\"] = study_df_trt[\"ID\"].astype(int)\n",
    "study_df_trt[\"SCHID\"] = study_df_trt[\"SCHID\"].astype(int)\n",
    "study_df_trt[\"UID\"] = study_df_trt[\"UID\"].astype(int)\n",
    "\n",
    "#get dummies and save file -- no need for data imputation\n",
    "study_df_trt = pd.get_dummies(study_df_trt,drop_first=True)\n",
    "study_df_trt.to_csv(\"data/full_unimputed_trt_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42aba044-063f-4509-945e-9eaff7fb5cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22721, 222)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint for saving dataframe and reloading it\n",
    "response_vars_df1 = pd.read_csv(\"data/full_unimputed_response_df.csv\").iloc[:,1:]\n",
    "response_vars_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8211941d-0b08-49f2-b2e8-d971a28b45e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22721, 157)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a second checkpoint\n",
    "predictor_vars_df1 = (pd.read_csv(\"data/full_imputed_predictor_df_iter0.csv\")).iloc[:,1:]\n",
    "predictor_vars_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ab3fc9b-9715-4746-86d1-e6aea38c1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cnum(cnum_var):\n",
    "    \"\"\"\n",
    "    Given a string, return the values after initial numeric values\n",
    "    \"\"\"\n",
    "    cnum_var = cnum_var[1:]\n",
    "    nums = cnum_var.rstrip('0123456789')\n",
    "    var_name = cnum_var[len(nums):]\n",
    "    return var_name\n",
    "\n",
    "#(Q 3.2 -- Baseline Anti-Conflic Score)\n",
    "def create_composite_vars(full_df,predictors=True):\n",
    "    \"\"\"\n",
    "    Construct the Baseline and Final Anti-Conflict scores. \n",
    "    \"\"\"\n",
    "    \n",
    "    #determine variables to include based on whether they are predictors\n",
    "    #manipulate variable names and string variables to ensure that predictor\n",
    "    #and response variables have aligned syntax\n",
    "    if predictors: \n",
    "        trs = \"\"\n",
    "        colname = \"Baseline_Conflict_Score\"\n",
    "        full_df.columns = [col.replace(\"(\",\"DUMMY\").split(\")\")[0] for col in full_df.columns]\n",
    "    else:\n",
    "        trs = \"W2\"\n",
    "        colname=\"Composite_Conflict_Score\"\n",
    "    \n",
    "    #get total number of disciplinary records for a student\n",
    "    de_var_names = [col for col in full_df.columns if \"DE\" in col]\n",
    "    full_df[\"DE_sum\"] = full_df.loc[:,de_var_names].sum(axis=1)\n",
    "    \n",
    "    #create lists of variables based on the number of possible responses\n",
    "    #and whether high positive values (e.g. TRUE, Often, Always) contribute\n",
    "    #positively or negatively to the anti-conflict scores\n",
    "    binary_positive_vars = [col for col in [(str(col).upper())+\"_DUMMY1\" for col in (\"dncl10w2,dncl11w2,dncl12w2,pncl1w2,pncl2w2,\"+\\\n",
    "                            \"pncl7w2,pncl12w2,pncl13w2,cscaw2,clhcw2,flihcw2,tomenw2,\"+\\\n",
    "                            \"tomepgw2,tomelnw2,tomesuw2,tomehdw2,dncl9w2,dncl10w2,dncl11w2,\"+\\\n",
    "                            \"dncl12w2,cbnpw2\".replace(\"w2\",trs)).split(\",\")] if col in full_df.columns]\n",
    "    binary_negative_vars = [col for col in [(str(col).upper())+\"_DUMMY1\" for col in (\"dncl1w2,dncl2w2,dncl3w2,dncl4w2,dncl5w2,dncl6w2,\"+\\\n",
    "                            \"dncl7w2,dncl8w2,dncl14w2,pncl3w2,pncl4w2,pncl5w2,pncl6w2,cilw2,cflw2,\"+\\\n",
    "                            \"cmosw2,cbiw2,cgiw2,tomeew2,tomempw2,tomergw2,\"+\\\n",
    "                            \"tomerbw2,tomemfw2,tomepmw2,tomethpw2,tomerew2,tomesgw2\"\\\n",
    "                                                                     .replace(\"w2\",trs)).split(\",\")] if col in full_df.columns]\n",
    "    cat3_positive_vars = [col for col in [col+str(i) for col in [(str(col).upper())+\"_DUMMY\" for col in \\\n",
    "                          (\"infdw2,infcw2\".replace(\"w2\",trs))\\\n",
    "                                                 .split(\",\")] for i in range(1,3)] if col in full_df.columns]\n",
    "    cat4_positive_vars = [col for col in [col+str(i) for col in [(str(col).upper())+\"_DUMMY\" for col in \\\n",
    "                          (\"dn9w2,dn10w2,dn11w2,dn12w2\".replace(\"w2\",trs))\\\n",
    "                                                 .split(\",\")] for i in range(1,4)] if col in full_df.columns]\n",
    "    cat4_negative_vars = [col for col in [col+str(i) for col in [(str(col).upper())+\"_DUMMY\" for col in \\\n",
    "                          (\"dn14w2,dn1w2,dn2w2,dn3w2,dn4w2,dn5w2,dn6w2,dn7w2,dn8w2\".replace(\"w2\",trs))\\\n",
    "                                                 .split(\",\")]\\\n",
    "                           for i in range(1,4)] if col in full_df.columns]\n",
    "    cat5_positive_vars = [col for col in [col+str(i) for col in [(str(col).upper())+\"_DUMMY\" for col in \\\n",
    "                          (\"pn1w2,pn2w2,pn10w2,pn11w2,pn12w2,pn13w2\".replace(\"w2\",trs)).split(\",\")]\\\n",
    "                          for i in range(1,5)] if col in full_df.columns]\n",
    "    cat5_negative_vars = [col for col in [col+str(i) for col in [(str(col).upper())+\"_DUMMY\" for col in \\\n",
    "                          (\"pn3w2,pn4w2,pn5w2,pn6w2,pn7w2,pn9w2\".replace(\"w2\",trs)).split(\",\")]\\\n",
    "                           for i in range(1,5)] if col in full_df.columns]\n",
    "    #cat3_negative_vars: none\n",
    "    \n",
    "    #aggregate variables by the aforementioned variable lists\n",
    "    full_df[\"binary_vars\"] = full_df.loc[:,binary_positive_vars]\\\n",
    "    .sum(axis=1) - full_df.loc[:,binary_negative_vars].sum(axis=1)\n",
    "\n",
    "    #combine survey results with disciplinary records to produce\n",
    "    #a final anti-conflict score\n",
    "    comp_var = full_df[\"binary_vars\"] - \\\n",
    "    (full_df[\"DE_sum\"] * 0.25)\n",
    "\n",
    "    return comp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d02604b-a395-4cc3-99bd-5d4cb5262ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGEC_NEW', 'GPA', 'GENDER_(1) Boy', 'GR_(1) 6th grade',\n",
      "       'GR_(2) 7th grade', 'GR_(3) 8th grade', 'COLL_(1) Yes',\n",
      "       'COLL_(2) Maybe', 'COLL_(3) Don't know',\n",
      "       'CELL_(1) Cell phone without Internet',\n",
      "       ...\n",
      "       'TOMEMP_(1) Yes', 'TOMELN_(1) Yes', 'TOMERG_(1) Yes', 'TOMERB_(1) Yes',\n",
      "       'TOMEMF_(1) Yes', 'TOMEPM_(1) Yes', 'TOMETHP_(1) Yes', 'TOMERE_(1) Yes',\n",
      "       'TOMESG_(1) Yes', 'TOMESU_(1) Yes'],\n",
      "      dtype='object', length=157)\n",
      "Index(['DE1', 'DE2', 'DE3', 'DE4', 'DE5', 'DE6', 'DE7', 'DE8', 'DE9', 'DE10',\n",
      "       ...\n",
      "       'TOMELNW2_DUMMY1', 'TOMERGW2_DUMMY1', 'TOMERBW2_DUMMY1',\n",
      "       'TOMEMFW2_DUMMY1', 'TOMEPMW2_DUMMY1', 'TOMETHPW2_DUMMY1',\n",
      "       'TOMEREW2_DUMMY1', 'TOMESGW2_DUMMY1', 'TOMESUW2_DUMMY1',\n",
      "       'TOMEHDW2_DUMMY1'],\n",
      "      dtype='object', length=222)\n"
     ]
    }
   ],
   "source": [
    "#create the Baseline_Conflict_Score (aka Baseline Anti-conflict Score)\n",
    "predictor_comp_df1 = predictor_vars_df1.copy()\n",
    "predictor_comp_df1[\"Baseline_Conflict_Score\"] = create_composite_vars(predictor_vars_df1,predictors=True)\n",
    "\n",
    "#create the Composite_Conflict_Score (AKA final anti-conflict score)\n",
    "response_comp_df1 = response_vars_df1.copy()\n",
    "response_comp_df1[\"Composite_Conflict_Score\"] = create_composite_vars(response_vars_df1,predictors=False)\n",
    "\n",
    "#get treatment variables\n",
    "trt_comp_df1 = pd.read_csv(\"data/full_unimputed_trt_df.csv\")\n",
    "\n",
    "#concatenate covariate/confounder, treatment, and response variables into one dataframe\n",
    "complete_vars_df1 = pd.concat([trt_comp_df1,response_vars_df1, response_comp_df1,\n",
    "                               predictor_vars_df1, predictor_comp_df1],axis=1)\n",
    "\n",
    "complete_vars_df1.to_csv(\"data/preprocessed_conflict_data_iter0MICE.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
